{
 "cells": [
  {
   "cell_type": "code",
   "id": "c92fb9f9f2e8b048",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-25T08:36:56.811031Z",
     "start_time": "2025-04-25T08:36:56.744649Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from tensorflow.keras import layers, models, backend as K\n",
    "%matplotlib inline\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # 中文显示\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T08:37:03.635468Z",
     "start_time": "2025-04-25T08:37:03.618847Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ========== 1. 数据加载与预处理 ==========\n",
    "def load_data(file_path):\n",
    "    \"\"\"加载并预处理CMAPSS数据集\"\"\"\n",
    "    # 定义完整的列名（根据PHM08数据集规范）\n",
    "    column_names = [\n",
    "        'unit', 'time', \n",
    "        'op_setting_1', 'op_setting_2', 'op_setting_3',\n",
    "        'sm_1', 'sm_2', 'sm_3', 'sm_4', 'sm_5', 'sm_6',\n",
    "        'sm_7', 'sm_8', 'sm_9', 'sm_10', 'sm_11', 'sm_12',\n",
    "        'sm_13', 'sm_14', 'sm_15', 'sm_16', 'sm_17', 'sm_18',\n",
    "        'sm_19', 'sm_20', 'sm_21'\n",
    "    ]\n",
    "    \n",
    "    # 读取数据并清理\n",
    "    df = pd.read_csv(file_path, sep=' ', header=None)\n",
    "    df.dropna(axis=1, how='all', inplace=True)\n",
    "    df.columns = column_names[:df.shape[1]]\n",
    "    return df"
   ],
   "id": "9311d4843d0467d4",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T08:37:07.569404Z",
     "start_time": "2025-04-25T08:37:07.559138Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def select_and_scale_sensors(df, selected_sensors):\n",
    "    \"\"\"选择并预处理传感器数据\"\"\"\n",
    "    # 验证传感器存在性\n",
    "    missing = [s for s in selected_sensors if s not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"缺少传感器: {missing}\")\n",
    "    \n",
    "    # 按发动机分组处理\n",
    "    engines = []\n",
    "    for unit_id in df['unit'].unique():\n",
    "        engine_df = df[df['unit'] == unit_id]\n",
    "        \n",
    "        # 提取并缩放传感器数据\n",
    "        sensor_data = engine_df[selected_sensors].values\n",
    "        scaled_data = MinMaxScaler(feature_range=(-1, 1)).fit_transform(sensor_data)\n",
    "        \n",
    "        engines.append(scaled_data)\n",
    "    \n",
    "    print(f\"成功预处理 {len(engines)} 台发动机数据\")\n",
    "    print(f\"使用的传感器: {selected_sensors}\")\n",
    "    return engines"
   ],
   "id": "884f8e2a8f8dcb37",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T08:37:11.510026Z",
     "start_time": "2025-04-25T08:37:11.481330Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ========== 2. VAE模型构建 ==========\n",
    "class VAEDetector:\n",
    "    \"\"\"变分自编码器异常检测器\"\"\"\n",
    "    def __init__(self, input_dim, latent_dim=8):\n",
    "        self.input_dim = input_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self._build_model()\n",
    "    \n",
    "    def _build_model(self):\n",
    "        # 编码器\n",
    "        inputs = layers.Input(shape=(self.input_dim,))\n",
    "        x = layers.Dense(32, activation='relu')(inputs)\n",
    "        x = layers.Dense(16, activation='relu')(x)\n",
    "        \n",
    "        # 潜在空间\n",
    "        z_mean = layers.Dense(self.latent_dim)(x)\n",
    "        z_log_var = layers.Dense(self.latent_dim)(x)\n",
    "        \n",
    "        # 重参数化\n",
    "        def sampling(args):\n",
    "            z_mean, z_log_var = args\n",
    "            epsilon = K.random_normal(shape=(K.shape(z_mean)[0], self.latent_dim))\n",
    "            return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "            \n",
    "        z = layers.Lambda(sampling)([z_mean, z_log_var])\n",
    "        \n",
    "        # 解码器\n",
    "        decoder_input = layers.Input(shape=(self.latent_dim,))\n",
    "        d = layers.Dense(16, activation='relu')(decoder_input)\n",
    "        d = layers.Dense(32, activation='relu')(d)\n",
    "        outputs = layers.Dense(self.input_dim, activation='tanh')(d)\n",
    "        \n",
    "        # 编译模型\n",
    "        self.encoder = models.Model(inputs, z_mean)\n",
    "        self.decoder = models.Model(decoder_input, outputs)\n",
    "        \n",
    "        vae_outputs = self.decoder(z)\n",
    "        self.vae = models.Model(inputs, vae_outputs)\n",
    "        \n",
    "        # 自定义损失\n",
    "        reconstruction_loss = K.mean(K.square(inputs - vae_outputs), axis=-1)\n",
    "        kl_loss = -0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "        self.vae.add_loss(K.mean(reconstruction_loss + kl_loss))\n",
    "        self.vae.compile(optimizer='adam')"
   ],
   "id": "58b048ef001433d4",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T08:37:15.329326Z",
     "start_time": "2025-04-25T08:37:15.320293Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ========== 3. 异常检测 ==========\n",
    "def find_anomaly_point(engine_data, model, smooth_window=10, detect_window_ratio=0.1, sigma=3):\n",
    "    \"\"\"检测异常起始点\"\"\"\n",
    "    # 计算重构误差\n",
    "    reconstructions = model.vae.predict(engine_data)\n",
    "    mse = np.mean(np.square(engine_data - reconstructions), axis=1)\n",
    "    \n",
    "    # 滑动平均\n",
    "    window = np.ones(smooth_window)/smooth_window\n",
    "    smoothed = np.convolve(mse, window, mode='valid')\n",
    "    \n",
    "    # 动态阈值\n",
    "    baseline = smoothed[:int(len(smoothed)*0.25)]\n",
    "    upper = baseline.mean() + sigma * baseline.std()\n",
    "    lower = baseline.mean() - sigma * baseline.std()\n",
    "    \n",
    "    # 检测持续异常\n",
    "    detect_window = max(int(len(engine_data)*detect_window_ratio), 1)\n",
    "    exceed = np.where((smoothed > upper) | (smoothed < lower))[0]\n",
    "    \n",
    "    for idx in exceed:\n",
    "        end = idx + detect_window\n",
    "        if end >= len(smoothed):\n",
    "            continue\n",
    "        if (smoothed[idx:end] > upper).all() or (smoothed[idx:end] < lower).all():\n",
    "            return idx + smooth_window - 1  # 转回原始索引\n",
    "    \n",
    "    return len(engine_data)"
   ],
   "id": "26a384ed3ad77aa2",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T08:37:18.730542Z",
     "start_time": "2025-04-25T08:37:18.722718Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ========== 4. 健康指标生成 ==========\n",
    "def generate_health_indicator(engine_data, model, selected_sensors, detect_params):\n",
    "    \"\"\"生成健康指标曲线\"\"\"\n",
    "    # 检测异常点\n",
    "    anomaly_point = find_anomaly_point(engine_data, model, **detect_params)\n",
    "    total_cycles = len(engine_data)\n",
    "    \n",
    "    # 初始化HI\n",
    "    HI = np.ones(total_cycles)\n",
    "    \n",
    "    if anomaly_point < total_cycles - 10:  # 需要足够的数据进行退化建模\n",
    "        # PCA特征融合\n",
    "        scaler = StandardScaler().fit(engine_data[:anomaly_point, selected_sensors])\n",
    "        normalized_data = scaler.transform(engine_data[:, selected_sensors])\n",
    "        \n",
    "        pca = PCA(n_components=1).fit(normalized_data[:anomaly_point])\n",
    "        pca_scores = pca.transform(normalized_data).flatten()\n",
    "        \n",
    "        # 确保退化方向正确\n",
    "        if np.corrcoef(pca_scores[anomaly_point:], np.arange(len(pca_scores[anomaly_point:])))[0,1] < 0:\n",
    "            pca_scores = -pca_scores\n",
    "        \n",
    "        # 归一化处理\n",
    "        hi_degradation = MinMaxScaler().fit_transform(pca_scores.reshape(-1,1)).flatten()\n",
    "        \n",
    "        # 应用指数平滑\n",
    "        alpha = 0.3\n",
    "        smoothed_hi = hi_degradation.copy()\n",
    "        for i in range(1, len(smoothed_hi)):\n",
    "            smoothed_hi[i] = alpha*hi_degradation[i] + (1-alpha)*smoothed_hi[i-1]\n",
    "        \n",
    "        # 调整范围到[1,0]\n",
    "        HI = 1 - (smoothed_hi - smoothed_hi.min())/(smoothed_hi.max() - smoothed_hi.min())\n",
    "    \n",
    "    return HI, anomaly_point"
   ],
   "id": "5e769e683ce54325",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T08:37:25.147627Z",
     "start_time": "2025-04-25T08:37:25.138603Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ========== 5. 可视化 ==========\n",
    "def plot_health_status(engine_data, HI, anomaly_point, sensor_names):\n",
    "    \"\"\"综合可视化健康状态\"\"\"\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    \n",
    "    # 传感器数据\n",
    "    plt.subplot(121)\n",
    "    for i in range(3):  # 显示前3个传感器\n",
    "        plt.plot(engine_data[:, i], label=sensor_names[i], alpha=0.7)\n",
    "    plt.axvline(anomaly_point, color='r', linestyle='--', linewidth=2)\n",
    "    plt.title('传感器数据监测')\n",
    "    plt.xlabel('运行周期')\n",
    "    plt.ylabel('归一化值')\n",
    "    plt.legend()\n",
    "    \n",
    "    # 健康指标\n",
    "    plt.subplot(122)\n",
    "    plt.plot(HI, color='darkorange', linewidth=2)\n",
    "    plt.axvline(anomaly_point, color='r', linestyle='--', label=f'异常起始点 ({anomaly_point})')\n",
    "    plt.ylim(-0.1, 1.1)\n",
    "    plt.title('健康指标 (HI) 退化曲线')\n",
    "    plt.xlabel('运行周期')\n",
    "    plt.ylabel('健康指标')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "cd6ec5a18b295d9d",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T08:37:36.870168Z",
     "start_time": "2025-04-25T08:37:36.864279Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 配置参数\n",
    "SELECTED_SENSORS = ['sm_2', 'sm_3', 'sm_4', 'sm_7', 'sm_8', 'sm_9',\n",
    "                       'sm_11', 'sm_12', 'sm_13', 'sm_14', 'sm_15', 'sm_17', 'sm_20', 'sm_21']\n",
    "DETECT_PARAMS = {\n",
    "        'smooth_window': 10,\n",
    "        'detect_window_ratio': 0.1,\n",
    "        'sigma': 3\n",
    "    }\n",
    "VAE_PARAMS = {\n",
    "        'input_dim': len(SELECTED_SENSORS),\n",
    "        'latent_dim': 8\n",
    "    }"
   ],
   "id": "8e400687049293b2",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T08:37:40.565175Z",
     "start_time": "2025-04-25T08:37:40.409543Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. 加载数据\n",
    "print(\"正在加载数据...\")\n",
    "df = load_data(\"data/train_FD001.txt\")\n",
    "engines = select_and_scale_sensors(df, SELECTED_SENSORS)"
   ],
   "id": "a060bb60cd3f44c2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载数据...\n",
      "成功预处理 100 台发动机数据\n",
      "使用的传感器: ['sm_2', 'sm_3', 'sm_4', 'sm_7', 'sm_8', 'sm_9', 'sm_11', 'sm_12', 'sm_13', 'sm_14', 'sm_15', 'sm_17', 'sm_20', 'sm_21']\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T08:39:23.484080Z",
     "start_time": "2025-04-25T08:37:48.286376Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 2. 训练VAE\n",
    "print(\"\\n训练VAE模型中...\")\n",
    "detector = VAEDetector(**VAE_PARAMS)\n",
    "train_data = np.vstack(engines)\n",
    "detector.vae.fit(train_data, epochs=100, batch_size=32, verbose=1)   "
   ],
   "id": "2cdb870cd280513e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "训练VAE模型中...\n",
      "Epoch 1/100\n",
      "645/645 [==============================] - 2s 1ms/step - loss: 0.1943\n",
      "Epoch 2/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1766\n",
      "Epoch 3/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1758\n",
      "Epoch 4/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1754\n",
      "Epoch 5/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1754\n",
      "Epoch 6/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1753\n",
      "Epoch 7/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1752\n",
      "Epoch 8/100\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.1752\n",
      "Epoch 9/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1752\n",
      "Epoch 10/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1752\n",
      "Epoch 11/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1751\n",
      "Epoch 12/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1751\n",
      "Epoch 13/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1751\n",
      "Epoch 14/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1750\n",
      "Epoch 15/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1751\n",
      "Epoch 16/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1751\n",
      "Epoch 17/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1751\n",
      "Epoch 18/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1750\n",
      "Epoch 19/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1750\n",
      "Epoch 20/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1751\n",
      "Epoch 21/100\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.1750\n",
      "Epoch 22/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1750\n",
      "Epoch 23/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1751\n",
      "Epoch 24/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1750\n",
      "Epoch 25/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1751\n",
      "Epoch 26/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1751\n",
      "Epoch 27/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1750\n",
      "Epoch 28/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1751\n",
      "Epoch 29/100\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.1751\n",
      "Epoch 30/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1751\n",
      "Epoch 31/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1751\n",
      "Epoch 32/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1751\n",
      "Epoch 33/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1750\n",
      "Epoch 34/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1750\n",
      "Epoch 35/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1751\n",
      "Epoch 36/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1751\n",
      "Epoch 37/100\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.1751\n",
      "Epoch 38/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1750\n",
      "Epoch 39/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1750\n",
      "Epoch 40/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1751\n",
      "Epoch 41/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1751\n",
      "Epoch 42/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1750\n",
      "Epoch 43/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1751\n",
      "Epoch 44/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1750\n",
      "Epoch 45/100\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.1751\n",
      "Epoch 46/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1751\n",
      "Epoch 47/100\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.1751\n",
      "Epoch 48/100\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.1751\n",
      "Epoch 49/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1750\n",
      "Epoch 50/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1751\n",
      "Epoch 51/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1751\n",
      "Epoch 52/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1750\n",
      "Epoch 53/100\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.1751\n",
      "Epoch 54/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1750\n",
      "Epoch 55/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1751\n",
      "Epoch 56/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1750\n",
      "Epoch 57/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1751\n",
      "Epoch 58/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1750\n",
      "Epoch 59/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1751\n",
      "Epoch 60/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1750\n",
      "Epoch 61/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1750\n",
      "Epoch 62/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1750\n",
      "Epoch 63/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1751\n",
      "Epoch 64/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1751\n",
      "Epoch 65/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1751\n",
      "Epoch 66/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1751\n",
      "Epoch 67/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1751\n",
      "Epoch 68/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1751\n",
      "Epoch 69/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1751\n",
      "Epoch 70/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1751\n",
      "Epoch 71/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1751\n",
      "Epoch 72/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1750\n",
      "Epoch 73/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1751\n",
      "Epoch 74/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1751\n",
      "Epoch 75/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1750\n",
      "Epoch 76/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1750\n",
      "Epoch 77/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1750\n",
      "Epoch 78/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1751\n",
      "Epoch 79/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1750\n",
      "Epoch 80/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1751\n",
      "Epoch 81/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1750\n",
      "Epoch 82/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1751\n",
      "Epoch 83/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1751\n",
      "Epoch 84/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1751\n",
      "Epoch 85/100\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.1751\n",
      "Epoch 86/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1751\n",
      "Epoch 87/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1751\n",
      "Epoch 88/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1751\n",
      "Epoch 89/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1751\n",
      "Epoch 90/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1750\n",
      "Epoch 91/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1750\n",
      "Epoch 92/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1750\n",
      "Epoch 93/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1751\n",
      "Epoch 94/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1751\n",
      "Epoch 95/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1751\n",
      "Epoch 96/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1751\n",
      "Epoch 97/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1750\n",
      "Epoch 98/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1750\n",
      "Epoch 99/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1751\n",
      "Epoch 100/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 0.1751\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24954d2a650>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T08:39:38.859682Z",
     "start_time": "2025-04-25T08:39:35.956676Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 3. 生成健康指标\n",
    "sensor_indices = [df.columns.get_loc(s) for s in SELECTED_SENSORS]\n",
    "engine_id = 0  # 选择第一台发动机演示\n",
    "    \n",
    "HI, anomaly = generate_health_indicator(\n",
    "        engines[engine_id], \n",
    "        detector,\n",
    "        sensor_indices,\n",
    "        DETECT_PARAMS\n",
    "    )   "
   ],
   "id": "ddaeca563ac60040",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 15 is out of bounds for axis 1 with size 14",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 5\u001B[0m\n\u001B[0;32m      2\u001B[0m sensor_indices \u001B[38;5;241m=\u001B[39m [df\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mget_loc(s) \u001B[38;5;28;01mfor\u001B[39;00m s \u001B[38;5;129;01min\u001B[39;00m SELECTED_SENSORS]\n\u001B[0;32m      3\u001B[0m engine_id \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m  \u001B[38;5;66;03m# 选择第一台发动机演示\u001B[39;00m\n\u001B[1;32m----> 5\u001B[0m HI, anomaly \u001B[38;5;241m=\u001B[39m \u001B[43mgenerate_health_indicator\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m        \u001B[49m\u001B[43mengines\u001B[49m\u001B[43m[\u001B[49m\u001B[43mengine_id\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdetector\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[43m        \u001B[49m\u001B[43msensor_indices\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[43m        \u001B[49m\u001B[43mDETECT_PARAMS\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[7], line 13\u001B[0m, in \u001B[0;36mgenerate_health_indicator\u001B[1;34m(engine_data, model, selected_sensors, detect_params)\u001B[0m\n\u001B[0;32m      9\u001B[0m HI \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mones(total_cycles)\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m anomaly_point \u001B[38;5;241m<\u001B[39m total_cycles \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m10\u001B[39m:  \u001B[38;5;66;03m# 需要足够的数据进行退化建模\u001B[39;00m\n\u001B[0;32m     12\u001B[0m     \u001B[38;5;66;03m# PCA特征融合\u001B[39;00m\n\u001B[1;32m---> 13\u001B[0m     scaler \u001B[38;5;241m=\u001B[39m StandardScaler()\u001B[38;5;241m.\u001B[39mfit(\u001B[43mengine_data\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43manomaly_point\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mselected_sensors\u001B[49m\u001B[43m]\u001B[49m)\n\u001B[0;32m     14\u001B[0m     normalized_data \u001B[38;5;241m=\u001B[39m scaler\u001B[38;5;241m.\u001B[39mtransform(engine_data[:, selected_sensors])\n\u001B[0;32m     16\u001B[0m     pca \u001B[38;5;241m=\u001B[39m PCA(n_components\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mfit(normalized_data[:anomaly_point])\n",
      "\u001B[1;31mIndexError\u001B[0m: index 15 is out of bounds for axis 1 with size 14"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 4. 可视化结果\n",
    "print(f\"\\n发动机 {engine_id+1} 分析结果：\")\n",
    "print(f\"- 总运行周期: {len(engines[engine_id])}\")\n",
    "print(f\"- 异常起始点: {anomaly}\")\n",
    "print(f\"- 剩余使用寿命: {len(engines[engine_id]) - anomaly} 周期\")"
   ],
   "id": "4fd286471000024c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "plot_health_status(engines[engine_id], HI, anomaly, SELECTED_SENSORS[:3])",
   "id": "initial_id"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
